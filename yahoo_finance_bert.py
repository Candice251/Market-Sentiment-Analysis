# -*- coding: utf-8 -*-
"""Yahoo_Finance_BERT

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iYNF1Rrb3tZTh5GgVK8A2l9cn0yXDsaP
"""

!pip install simpletransformers yfinance

import pandas as pd
import yfinance as yf
from simpletransformers.classification import ClassificationModel

from google.colab import drive
drive.mount('/content/drive')

model_path = '/content/drive/MyDrive/fiisual_project/bert_model'

model = ClassificationModel(
  'bert',
  model_path,
  num_labels=3,
  use_cuda=False
)

news_df = pd.read_csv('/content/drive/MyDrive/fiisual_project/yahoo_finance_data.csv')
news_df.head()

print(news_df['Date'].min(), news_df['Date'].max())

news_df.info()

import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(14, 6))
daily_counts = news_df.groupby('Date').size()

plt.bar(daily_counts.index, daily_counts.values, color='skyblue', alpha=0.7)
plt.xlabel('Date')
plt.ylabel('Number of Articles')
plt.title('Daily News Volume (Frequency)', fontsize=15)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# 確保 Date 欄位是 datetime 格式，方便比較
news_df['Date'] = pd.to_datetime(news_df['Date'])

news_df = news_df[news_df['Date'] >= '2025-12-16']
print(f"過濾後的剩餘資料量: {len(news_df)}")
print(news_df['Date'].value_counts().sort_index())

import re
def clean_finance_text(text):
    # 1. 轉小寫
    text = text.lower()
    # 2. 去除 URL 與 HTML 標籤
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    # 3. 去除標點符號與特殊數字
    text = re.sub(r'[^\w\s%]', '', text)
    # 4. 去除多餘空格
    text = text.strip()
    return text

news_df['Cleaned_Title'] = news_df['Title'].apply(clean_finance_text)
news_df

import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta

predictions, raw_outputs = model.predict(news_df['Cleaned_Title'].tolist())

news_df['pred_label'] = predictions
def label(label):
    if label == 0: return "Negative"
    if label == 1: return "Neutral"
    if label == 2: return "Positive"
    return 0

news_df['sentiment'] = news_df['pred_label'].apply(label)

news_df

plt.figure(figsize=(8, 5))
sns.countplot(x='sentiment', data=news_df)
plt.title('Sentiment Distribution Predicted in Yahoo Finance News')
plt.show()

# 計算比例
print(news_df['sentiment'].value_counts(normalize=True))

score_map = {0: -1, 1: 0, 2: 1}
news_df['sentiment_score'] = news_df['pred_label'].map(score_map)
daily_sentiment = news_df.groupby('Date')['sentiment_score'].mean()

print(daily_sentiment)

from datetime import timedelta

if isinstance(daily_sentiment, pd.Series):
    daily_sentiment = daily_sentiment.reset_index()

col_name = daily_sentiment.columns[1]
daily_final = daily_sentiment.rename(columns={col_name: 'Score_Daily'})

sentiment_all['Date'] = pd.to_datetime(sentiment_all['Date'])

# 下載股價資料
market_ticker = "^GSPC" # S&P 500
start_date = pd.to_datetime(news_df['Date'].min()) - timedelta(days=5)
end_date = pd.to_datetime(news_df['Date'].max()) + timedelta(days=5)

price_df = yf.download(market_ticker, start=start_date, end=end_date, progress=False)

# 處理 yfinance 可能產生的 MultiIndex
if isinstance(price_df.columns, pd.MultiIndex):
    price_df.columns = price_df.columns.droplevel(1)

price_df = price_df.reset_index()
price_df['Date'] = pd.to_datetime(price_df['Date'])

merged_df = pd.merge(price_df, daily_final, on='Date', how='inner')

merged_df.head()

merged_df['Score_Shift1'] = merged_df['Score_Daily'].shift(1) #看昨天的新聞能不能預測今天
merged_df.head()

import matplotlib.dates as mdates

# 設定共用繪圖函數
def plot_dual_lines(df, sentiment_col, title, sent_label):
  sns.set(style="whitegrid")
  fig, ax1 = plt.subplots(figsize=(14, 6))

  dates = df['Date']

  # S&P500
  color_price = '#1f77b4'
  ax1.set_xlabel('Date')
  ax1.set_ylabel('S&P 500 Price', color=color_price, fontweight='bold', fontsize=12)
  line1 = ax1.plot(dates, df['Close'], color=color_price, linewidth=2.5, linestyle='-', label='S&P 500 Price')
  ax1.tick_params(axis='y', labelcolor=color_price)
  ax1.grid(True, alpha=0.3)

  # 情緒指標
  ax2 = ax1.twinx()
  color_sent = '#d62728'
  ax2.set_ylabel(sent_label, color=color_sent, fontweight='bold', fontsize=12)

  line2 = ax2.plot(dates, df[sentiment_col], color=color_sent, linewidth=2, linestyle='--', marker='o', markersize=4, label=sent_label)
  ax2.tick_params(axis='y', labelcolor=color_sent)

  baseline = 1.0 if df[sentiment_col].max() > 1.5 else 0.0
  ax2.axhline(baseline, color='black', alpha=0.4, linestyle='-', linewidth=1)

  lines = line1 + line2
  labels = [l.get_label() for l in lines]
  ax1.legend(lines, labels, loc='upper left', frameon=True, shadow=True)

  # 標題與排版
  plt.title(title, fontsize=15, pad=15)
  #plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=2))
  plt.gcf().autofmt_xdate()
  plt.tight_layout()
  plt.show()


# 單日情緒
plot_dual_lines(
    merged_df,
    'Score_Daily',
    '(A) Short-term Reaction: Price vs. Daily Sentiment Line',
    'Daily Sentiment Score'
)

# 趨勢情緒


# 預測訊號
plot_dual_lines(
    merged_df,
    'Score_Shift1',
    '(B) Predictive Power: Price vs. Lagged Sentiment (Yesterday\'s News)',
    'Lagged Score (T-1)'
)

from scipy import stats

df_test = merged_df.dropna().copy()



metrics = {
    "Daily Sentiment Score v.s. Stock Price": "Score_Daily",
    "Yesterday's Sentiment Score v.s Stock Price": "Score_Shift1"
}

for name, col in metrics.items():
  if col in df_test.columns:
    print(f"【{name}】")

    corr, p_val = stats.pearsonr(df_test[col], df_test['Close'])
    print(f"   - 相關係數: {corr:.4f}")
    print(f"   - P-value: {p_val:.4f}")

from scipy import stats

df_test = merged_df.dropna().copy()
df_test['Return'] = df_test['Close'].pct_change()
df_test = df_test.dropna()


metrics = {
    "Daily sentiment score v.s. Daily return": "Score_Daily",
    "Yesterday's sentiment score v.s Daily return": "Score_Shift1"
}

for name, col in metrics.items():
  if col in df_test.columns:
    print(f"【{name}】")

    corr, p_val = stats.pearsonr(df_test[col], df_test['Return'])
    print(f"   - 相關係數: {corr:.4f}")
    print(f"   - P-value: {p_val:.4f}")